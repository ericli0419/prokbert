{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b700d0-ff0e-4940-a2cc-8fbfe9873660",
   "metadata": {},
   "source": [
    "# Inference and Evaluation with the Finetuned Models\n",
    "\n",
    "In this notebook, we demonstrate how one can evaluate various finetuned models.\n",
    "\n",
    "The main steps are:\n",
    "  * Preparing the models and datasets\n",
    "  * Running inference and collecting the results for each dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77070a04-3f9c-4183-bbbf-832407b376e5",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "While ProkBERT can operate on CPUs, leveraging GPUs significantly accelerates the process. Google Colab offers free GPU usage (subject to time and memory limits), making it an ideal platform for trying and experimenting with ProkBERT models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffda82f-ddb0-4107-8ecb-0d9d2cd4bfc8",
   "metadata": {},
   "source": [
    "### Enabling and testing the GPU (if you are using google colab)\n",
    "\n",
    "First, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa017b-a043-4e54-8e0e-33638192f137",
   "metadata": {},
   "source": [
    "### Setting up the packages and the installs\n",
    "First, we'll install the ProkBERT package directly from its GitHub repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1fb310-003a-4f05-be02-b567fd0b62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProkBERT\n",
    "#!pip install datasets\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, roc_auc_score, recall_score\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cba33b-d853-4eb6-86c0-b9beeb28598e",
   "metadata": {},
   "source": [
    "Next, we'll confirm that we can connect to the GPU with pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dcfa647-993f-4c57-9dcc-38115b962ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: Quadro RTX 6000\n",
      "Number of available CPU cores: 96\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError('GPU device not found')\n",
    "else:\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f'Found GPU at: {device_name}')\n",
    "num_cores = os.cpu_count() \n",
    "print(f'Number of available CPU cores: {num_cores}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea0dc2-73ea-414e-a1d7-06a14ae3abbf",
   "metadata": {},
   "source": [
    "## Loading the Finetuned Model and the tokenizer for Promoter Identification\n",
    "\n",
    "Next, we will download the finetuned model for promoter identification. For more details about the model, please see the Finetuning notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb747085-7895-466f-bdd6-d2f010bd58f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/neuralbioinfo/prokbert-mini-promoter:\n",
      "- tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b575276ad3c4041b680efd865b85489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "models.py:   0%|          | 0.00/11.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/neuralbioinfo/prokbert-mini:\n",
      "- models.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678ed0f9e59c4ce1a8703a03cef037c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/82.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "finetuned_model = \"neuralbioinfo/prokbert-mini-promoter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model, trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finetuned_model, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a53937-5ddc-4b90-80d9-0839b4ea7ff1",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "In this section, we will evaluate the test sets of the promoter dataset. We have two different types of tests: a sigma70 test (known E. coli promoters) referred to as the 'test_sigma70' set, and a multispecies dataset, which consists of promoters from various species as well as CDS sequences (non-promoters) and randomly generated sequences. For a more detailed description, see: [Bacterial Promoters Dataset](https://huggingface.co/datasets/neuralbioinfo/bacterial_promoters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2238bf-a6c9-4906-98a5-02cc56d92d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Tokenize the input sequences\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        examples[\"segment\"],\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    # Return the updated dictionary\n",
    "    return encoded\n",
    "    \n",
    "dataset = load_dataset(\"neuralbioinfo/bacterial_promoters\", split='test_sigma70')\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=num_cores)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ada118-ef5e-4bc0-afa5-435c5f3083d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:11:59,469 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define TrainingArguments for inference\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",              # Directory for storing logs/results\n",
    "    per_device_eval_batch_size=128,     # Batch size for inference\n",
    "    logging_dir=\"./logs\",               # Directory for logs\n",
    "    report_to=\"none\",                   # Disable reporting to W&B or other loggers\n",
    ")\n",
    "\n",
    "# Initialize Trainer for inference\n",
    "trainer = Trainer(\n",
    "    model=model,                        # Pretrained ProkBERT model\n",
    "    args=training_args,                 # Inference arguments\n",
    ")\n",
    "\n",
    "# Perform inference\n",
    "predictions = trainer.predict(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "127f2c47-d6a1-483c-878e-b05b2f103b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m dataset_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob_class_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m probabilities[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     10\u001b[0m dataset_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_labels\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mace_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtools\u001b[39;00m; tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProkBERT Inference Results\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mdataset_df)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "probabilities = softmax(predictions.predictions, axis=1)\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n",
    "dataset_df = dataset.to_pandas()\n",
    "dataset_df[\"prob_class_0\"] = probabilities[:, 0]\n",
    "dataset_df[\"prob_class_1\"] = probabilities[:, 1]\n",
    "dataset_df[\"predicted_label\"] = predicted_labels\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"ProkBERT Inference Results\", dataframe=dataset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "471bf537-1934-4d34-b819-650557dd8b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>ppd_original_SpeciesName</th>\n",
       "      <th>Strand</th>\n",
       "      <th>segment</th>\n",
       "      <th>class_label</th>\n",
       "      <th>L</th>\n",
       "      <th>prom_class</th>\n",
       "      <th>y</th>\n",
       "      <th>prob_class_0</th>\n",
       "      <th>prob_class_1</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sigma70s_neg00000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>CAAGTCTTCATGTGAAGCAGAGAGCTACTATTAATATCGACGGTGT...</td>\n",
       "      <td>non_promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344011</td>\n",
       "      <td>0.655989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigma70s_neg00000001</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>GTACTTATGAGTAATTTACATAAACAATCTGACCGGACTGAATGTC...</td>\n",
       "      <td>non_promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.770286</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigma70s_neg00000002</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>GACGGACCCTTATTCACTTACGAACGCATTTCTTCTCTTGTATTGG...</td>\n",
       "      <td>non_promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831560</td>\n",
       "      <td>0.168440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigma70s_neg00000003</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ATACAATTTGTACACTGGAAAATCACAAGTAAAGGAAGGTCGCAAC...</td>\n",
       "      <td>non_promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.859872</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigma70s_neg00000004</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>TGTGCGTTGATGCCTCTATTTGTATGGAACAATGTTCCTGAATGAT...</td>\n",
       "      <td>non_promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302382</td>\n",
       "      <td>0.697618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>sigma70s_pos00000860</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>CGGTTGCCAACAACGTTCATAACTTTGTTGAGCACCGATACGCATT...</td>\n",
       "      <td>promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_pos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.469372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>sigma70s_pos00000861</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>TGCTCTCGTTTCCTAAGAGTTGTTGCATTTTGCTATATGTTACAAT...</td>\n",
       "      <td>promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_pos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095307</td>\n",
       "      <td>0.904693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>sigma70s_pos00000862</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>CTCGCTGTATCTCTGATAAAACTTGACTCTGGAGTCGACTCCAGAG...</td>\n",
       "      <td>promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_pos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>0.920192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>sigma70s_pos00000863</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>TATGTAACATAATGCGACCAATAATCGTAATGAATATGAGAAGTGT...</td>\n",
       "      <td>promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_pos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095940</td>\n",
       "      <td>0.904060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>sigma70s_pos00000864</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>TCGCACGGGTGGATAAGCGTTTACAGTTTTCGCAAGCTCGTAAAAG...</td>\n",
       "      <td>promoter</td>\n",
       "      <td>81</td>\n",
       "      <td>sigma70s_pos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141018</td>\n",
       "      <td>0.858982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1864 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                segment_id ppd_original_SpeciesName Strand  \\\n",
       "0     sigma70s_neg00000000                      nan    nan   \n",
       "1     sigma70s_neg00000001                      nan    nan   \n",
       "2     sigma70s_neg00000002                      nan    nan   \n",
       "3     sigma70s_neg00000003                      nan    nan   \n",
       "4     sigma70s_neg00000004                      nan    nan   \n",
       "...                    ...                      ...    ...   \n",
       "1859  sigma70s_pos00000860                      nan    nan   \n",
       "1860  sigma70s_pos00000861                      nan    nan   \n",
       "1861  sigma70s_pos00000862                      nan    nan   \n",
       "1862  sigma70s_pos00000863                      nan    nan   \n",
       "1863  sigma70s_pos00000864                      nan    nan   \n",
       "\n",
       "                                                segment   class_label   L  \\\n",
       "0     CAAGTCTTCATGTGAAGCAGAGAGCTACTATTAATATCGACGGTGT...  non_promoter  81   \n",
       "1     GTACTTATGAGTAATTTACATAAACAATCTGACCGGACTGAATGTC...  non_promoter  81   \n",
       "2     GACGGACCCTTATTCACTTACGAACGCATTTCTTCTCTTGTATTGG...  non_promoter  81   \n",
       "3     ATACAATTTGTACACTGGAAAATCACAAGTAAAGGAAGGTCGCAAC...  non_promoter  81   \n",
       "4     TGTGCGTTGATGCCTCTATTTGTATGGAACAATGTTCCTGAATGAT...  non_promoter  81   \n",
       "...                                                 ...           ...  ..   \n",
       "1859  CGGTTGCCAACAACGTTCATAACTTTGTTGAGCACCGATACGCATT...      promoter  81   \n",
       "1860  TGCTCTCGTTTCCTAAGAGTTGTTGCATTTTGCTATATGTTACAAT...      promoter  81   \n",
       "1861  CTCGCTGTATCTCTGATAAAACTTGACTCTGGAGTCGACTCCAGAG...      promoter  81   \n",
       "1862  TATGTAACATAATGCGACCAATAATCGTAATGAATATGAGAAGTGT...      promoter  81   \n",
       "1863  TCGCACGGGTGGATAAGCGTTTACAGTTTTCGCAAGCTCGTAAAAG...      promoter  81   \n",
       "\n",
       "        prom_class  y  prob_class_0  prob_class_1  predicted_label  \n",
       "0     sigma70s_neg  0      0.344011      0.655989                1  \n",
       "1     sigma70s_neg  0      0.770286      0.229714                0  \n",
       "2     sigma70s_neg  0      0.831560      0.168440                0  \n",
       "3     sigma70s_neg  0      0.859872      0.140128                0  \n",
       "4     sigma70s_neg  0      0.302382      0.697618                1  \n",
       "...            ... ..           ...           ...              ...  \n",
       "1859  sigma70s_pos  1      0.530628      0.469372                0  \n",
       "1860  sigma70s_pos  1      0.095307      0.904693                1  \n",
       "1861  sigma70s_pos  1      0.079808      0.920192                1  \n",
       "1862  sigma70s_pos  1      0.095940      0.904060                1  \n",
       "1863  sigma70s_pos  1      0.141018      0.858982                1  \n",
       "\n",
       "[1864 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33b24b-43c4-4ff5-b3a7-96f53a08b996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714c063-ced1-4be1-b5a1-89945ae50378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ece360-3760-4a55-8eba-937c02d24d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf210a2-1fd7-47b7-9e5b-a26dc1b19016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637aa42d-be37-4f94-9ab0-e0fbcb8cc6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe577a-488d-45e7-b3c4-cd4f1bbe417a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ff3c79e-f8f6-4ceb-8611-90f12a88b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:10:00,770 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.36701283,  0.27845627],\n",
       "       [ 0.632904  , -0.5770252 ],\n",
       "       [ 0.81924   , -0.77748686],\n",
       "       ...,\n",
       "       [-1.2759869 ,  1.168967  ],\n",
       "       [-1.1626655 ,  1.0805084 ],\n",
       "       [-0.9650734 ,  0.84178895]], dtype=float32), label_ids=None, metrics={'test_model_preparation_time': 0.0028, 'test_runtime': 1.0827, 'test_samples_per_second': 1721.666, 'test_steps_per_second': 13.855})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a86cf-4bce-4d5b-915c-1bfe426d218e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca833f16-f311-443c-a171-ed69bfc3d12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912a4df-24bd-44dc-b0ab-efab38eaaa68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d4b90-565e-427b-867d-be75aa441563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f98f2dd-48b0-4daf-96b2-a8d9f6eca397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d325877b54430b96a9e9f52e23f177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=96):   0%|          | 0/1864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7cbf910-16a5-4f04-b491-ff4e7ca0b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 16:10:57,844 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set the evaulation parameters, adjust the batch size if needed?\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=128,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args\n",
    ")\n",
    "predictions = trainer.predict(tokenized_dataset)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b6a06-0ce9-45f8-8fa0-197f8ccb88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497f6d0-4de9-4475-83fc-7966ea2138e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92989878-deec-4733-a5fa-bc7ff96d334a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de67d3-f33f-4475-b8c2-9fe175786deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd3984-f10e-477c-bb97-54fe91e53c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caad51-28c3-4ab7-a266-7194585129db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e70e6-4c17-43ce-8ca7-67559ece972b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c89670b-83c1-4f3b-9926-adb076d0d875",
   "metadata": {},
   "source": [
    "### Tokenization and PyTorch Dataset Creation\n",
    "\n",
    "Now that we have the tokenizer, the dataset can be prepared for evaluation. Here, we prepare the data for both sigma70 and multispecies datasets.\n",
    "\n",
    "#### Creating Datasets\n",
    "\n",
    "We will process the data into a format suitable for our PyTorch model. This involves tokenizing the sequences and converting them into a format that our model can understand. The following code will convert our `test_ms_db` (multispecies dataset) and `test_sigma70_db` (sigma70 dataset) into PyTorch datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f850bd-96d4-4f95-aae1-4b23261bc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating datasets!\n",
    "[X_test, y_test, torchdb_test] = get_torch_data_from_segmentdb_classification(tokenizer, test_ms_db)\n",
    "print(f'Processing validation database!')\n",
    "[X_val, y_val, torchdb_val] = get_torch_data_from_segmentdb_classification(tokenizer, test_sigma70_db)\n",
    "\n",
    "test_ds = ProkBERTTrainingDatasetPT(X_test, y_test, AddAttentionMask=True)\n",
    "val_ds = ProkBERTTrainingDatasetPT(X_val, y_val, AddAttentionMask=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d168a1-a02d-4b8a-849d-02009fdb534d",
   "metadata": {},
   "source": [
    "## Performing Inference and Evaluation\n",
    "\n",
    "Now that both the model and the data are prepared, we will perform inference and process the dataset.\n",
    "\n",
    "For simplicity, this demonstration will be conducted on a single GPU. An important parameter to consider is the batch size, which is set to 1024 in our example. Adjust this value according to the capabilities of your GPU to ensure efficient processing.\n",
    "\n",
    "In real-world scenarios, especially when evaluating large datasets (exceeding 1,000,000 samples), we recommend utilizing Torch Distributed Data Parallel (DDP) and compiled models for optimized performance. \n",
    "\n",
    "The prediction results will be aggregated into a list of numpy arrays, each containing the predicted label, ground truth label, and logits for each class (promoter vs. non-promoter). The evaluation metrics, including AUC, Matthews Correlation Coefficient (MCC), accuracy, and others, will be summarized and returned in a dictionary format.\n",
    "\n",
    "Below is the code to perform batch-wise inference and accumulate the prediction results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d807851-6dd4-45a3-b86d-ffa7e54e077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "dataloader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# Calculate the total number of batches\n",
    "total_batches = len(dataloader)\n",
    "\n",
    "pred_results_ls = []\n",
    "processed_batches = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}  # Move batch data to the appropriate device\n",
    "    with torch.no_grad():  # Inference mode: no gradient computation\n",
    "        outputs = model(**batch)\n",
    "    pred_results = evaluate_binary_classification_bert_build_pred_results(outputs['logits'], batch['labels'])\n",
    "    pred_results_ls.append(pred_results)  # Collecting prediction results\n",
    "    \n",
    "    processed_batches += 1  # Increment the count of processed batches\n",
    "    percent_complete = (processed_batches / total_batches) * 100  # Calculate the percentage of completion\n",
    "    print(f'Batch {processed_batches}/{total_batches} processed, {percent_complete:.2f}% complete.')  # Print the progress\n",
    "\n",
    "# Combine all batch results into one array for evaluation\n",
    "pred_results = np.concatenate(pred_results_ls)\n",
    "# Calculate and retrieve evaluation metrics\n",
    "eval_results, eval_results_ls = evaluate_binary_classification_bert(pred_results)\n",
    "\n",
    "# cleanup\n",
    "del model\n",
    "del batch\n",
    "del dataset\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame([eval_results])\n",
    "# Set more meaningful index name\n",
    "results_df.index = ['Metrics']\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fab1344-8d80-41bd-a3bd-3858499916f0",
   "metadata": {},
   "source": [
    "# Inference with the Phage Models\n",
    "\n",
    "In this section, we will walk through the evaluation of the phage test dataset, following a similar procedure to the previous example. The workflow includes:\n",
    "  * Preparing the model\n",
    "  * Preparing the dataset\n",
    "  * Evaluating the test set and measuring performance metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b52cd-72cf-45f7-a980-b6e67fd1cc1b",
   "metadata": {},
   "source": [
    "# Prearing the model: \n",
    "This is a simple model, that is trained using the 'MegatronBertForSequenceClassification' class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3daff-ac6f-4167-8ebf-dc0267cf9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MegatronBertForSequenceClassification\n",
    "\n",
    "finetuned_model = \"neuralbioinfo/prokbert-mini-phage\"\n",
    "kmer = 6\n",
    "shift= 1\n",
    "\n",
    "tok_params = {'kmer' : kmer,\n",
    "             'shift' : shift}\n",
    "tokenizer = ProkBERTTokenizer(tokenization_params=tok_params)\n",
    "model = MegatronBertForSequenceClassification.from_pretrained(finetuned_model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "_=model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8ea5a-2092-4c1a-aec3-eb45d78d0770",
   "metadata": {},
   "source": [
    "## Preparing the Phage Dataset for Evaluation\n",
    "\n",
    "In this section, we load and prepare the phage dataset for evaluation. The dataset is a smaller subset suitable for testing, named \"phage-test-small\". We will demonstrate how to load this dataset, convert it to a pandas DataFrame.\n",
    "\n",
    "First, we load the dataset and set the batch size for the DataLoader, which controls how many samples will be processed simultaneously. Then, we convert the loaded dataset to a pandas DataFrame for easier manipulation and processing. Finally, we prepare the data for PyTorch by tokenizing and converting it into a format suitable for our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9716080-e2f6-4751-ad40-fe6a68978236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"nerualbioinfo/phage-test-small\")\n",
    "batch_size = 64\n",
    "\n",
    "# Loading and converting the dataset\n",
    "test_set = dataset[\"sample_test_L1024\"].to_pandas()\n",
    "print(f'Processing the database!')\n",
    "[X, y, torchdb] = get_torch_data_from_segmentdb_classification(tokenizer, test_set)\n",
    "dataset = ProkBERTTrainingDatasetPT(X, y, AddAttentionMask=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d46472-d40a-4226-b2a4-7bbdd197e070",
   "metadata": {},
   "source": [
    "## Inference and Evaluation of the Phage Dataset\n",
    "\n",
    "In this part of the process, we will perform inference on the phage dataset using the prepared DataLoader. The objective is to process each batch from the dataset, make predictions using the finetuned model, and then compile these predictions for evaluation.\n",
    "\n",
    "We initiate an empty list, `pred_results_ls`, to store the prediction results from each batch. We iterate over each batch in the DataLoader, ensuring that the batch data is moved to the same device as the model (GPU or CPU). With gradient computation disabled (to enhance performance and reduce memory usage during inference), we pass the batch through the model to obtain output logits.\n",
    "\n",
    "For each batch's output, we evaluate the binary classification results using the `evaluate_binary_classification_bert_build_pred_results` function, which processes the model's logits and the actual labels to generate prediction results. These results are then appended to our list.\n",
    "\n",
    "After processing all batches, we concatenate the list of arrays into a single numpy array. This aggregated result allows us to evaluate the overall performance of the model on the entire test set. We use the `evaluate_binary_classification_bert` function to calculate various evaluation metrics such as accuracy, precision, recall, F1 score, etc., based on the compiled prediction results. The `eval_results` dictionary will store these metrics for review and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c12f4-8757-4153-89d3-cd41b3679f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of batches\n",
    "total_batches = len(dataloader)\n",
    "\n",
    "pred_results_ls = []\n",
    "processed_batches = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}  # Move batch data to the appropriate device\n",
    "    with torch.no_grad():  # Inference mode: no gradient computation\n",
    "        outputs = model(**batch)\n",
    "    pred_results = evaluate_binary_classification_bert_build_pred_results(outputs['logits'], batch['labels'])\n",
    "    pred_results_ls.append(pred_results)  # Collecting prediction results\n",
    "    \n",
    "    processed_batches += 1  # Increment the count of processed batches\n",
    "    percent_complete = (processed_batches / total_batches) * 100  # Calculate the percentage of completion\n",
    "    print(f'Batch {processed_batches}/{total_batches} processed, {percent_complete:.2f}% complete.')  # Print the progress\n",
    "\n",
    "# Combine all batch results into one array for evaluation\n",
    "pred_results = np.concatenate(pred_results_ls)\n",
    "# Calculate and retrieve evaluation metrics\n",
    "eval_results, eval_results_ls = evaluate_binary_classification_bert(pred_results)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame([eval_results])\n",
    "# Set more meaningful index name\n",
    "results_df.index = ['Metrics']\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124c6d5-c83a-4367-abe6-4ce5bff1a318",
   "metadata": {},
   "source": [
    "## Final Remarks\n",
    "\n",
    "In this evaluation, we have successfully executed the inference process using the pre-trained phage model and assessed its performance on the test dataset. Key metrics such as accuracy, F1 score, Matthews Correlation Coefficient (MCC), and Area Under the Curve (AUC) provide a comprehensive view of the model's ability to distinguish between classes.\n",
    "\n",
    "Additionally, while these results are promising, further validation and testing on independent datasets are recommended to ensure the model's generalizability and robustness. This could involve cross-validation, additional external datasets, or real-world applications.\n",
    "\n",
    "Finally, this notebook serves as a foundation for further exploration and refinement. Researchers are encouraged to experiment with different models, parameters, and datasets to enhance understanding and performance. The ultimate goal is to leverage these computational tools to advance our knowledge in microbiology and related fields.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
