{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88222642-c405-4efd-beda-471c100cfe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 09:13:59,832 - INFO - Dataset size: 482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PRETRAIN_CONFIG_FILE environment variable has not been set. Using default value: /home/ligeti/github/prokbert/src/prokbert/configs/pretraining.yaml\n",
      "SEQ_CONFIG_FILE environment variable has not been set. Using default value: /home/ligeti/github/prokbert/src/prokbert/configs/sequence_processing.yaml\n",
      "/home/ligeti/github/prokbert/src/prokbert\n",
      "/home/ligeti/github/prokbert/src/prokbert\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "import pathlib\n",
    "from os.path import join\n",
    "import os\n",
    "import sys\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "current_path = str(pathlib.Path(os.getcwd()).parent)\n",
    "sys.path.append(current_path)\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('../)\n",
    "\n",
    "from config_utils import *\n",
    "from sequtils import *\n",
    "from training_utils import *\n",
    "from prokbert_tokenizer import ProkBERTTokenizer\n",
    "from prok_datasets import IterableProkBERTPretrainingDataset\n",
    "from general_utils import *\n",
    "from ProkBERTDataCollator import *\n",
    "from transformers import MegatronBertConfig, MegatronBertForMaskedLM, Trainer, TrainingArguments\n",
    "\n",
    "    \n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "#pd.set_option('display.width', 4000)\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_model_output_dir = ''\n",
    "train_model_name = 'LCA_repr_k6s1_l2048hs1536_h16_l16_mlm02_rp8_rndp1_rkv'\n",
    "\n",
    "model_params = {'model_outputpath': '/scratch/fastscratch/NBL/trained_models/test/mini0',\n",
    "                'model_name' : 'mini0'}\n",
    "dataset_params = {'dataset_path' : '../data/preprocessed/pretraining.h5'}\n",
    "pretraining_params = {}\n",
    "\n",
    "\n",
    "prokbert_config = ProkBERTConfig()\n",
    "_ = prokbert_config.get_and_set_model_parameters(model_params)\n",
    "_ = prokbert_config.get_and_set_dataset_parameters(dataset_params)\n",
    "_ = prokbert_config.get_and_set_pretraining_parameters(pretraining_params)\n",
    "\n",
    "\n",
    "# Kell egy dataset\n",
    "hdf_file = '../data/preprocessed/pretraining.h5'\n",
    "\n",
    "ds = IterableProkBERTPretrainingDataset(hdf_file, input_batch_size=10000, max_iteration_over_ds=5)\n",
    "\n",
    "X = ds[0:3][:,0:10]\n",
    "#torch.stack(ds[0:3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73ec47-804e-4155-ab3c-08849c773eee",
   "metadata": {},
   "source": [
    "### Pretraining folyamata\n",
    "\n",
    "Vannak előkészítő feladatok:\n",
    "  * tokenizáló loadolása\n",
    "  * collator osztály loadolása\n",
    "  * Meglévő modellek ellenőrzése, checkpoint-ok ellenőrzése\n",
    "  * dataset betöltése és inicializálása, ellenőrzése (megfelel-e a követelményeknek vagy sem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf28f8e-e095-4444-a528-f7d48001d381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2a7794-694e-46d1-a6af-ba61394f2d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 09:14:05,009 - INFO - Loading the datacollator class!\n",
      "2023-08-15 09:14:05,009 - INFO - Collator Parameters:\n",
      "  Number of tokens masked to left:  3\n",
      "  Number of tokens masked to right: 2\n",
      "  Probability of restoring a masked token: 0.8\n",
      "  Probability of changing to a random token: 0.01\n",
      "  MLM Probability: 0.05\n",
      "  Default token type: torch.int16\n",
      "\n",
      "2023-08-15 09:14:05,010 - INFO - Checking whether the file exists or not!\n",
      "2023-08-15 09:14:05,010 - INFO - Loading and creating a IterableProkBERTPretrainingDataset\n",
      "2023-08-15 09:14:05,011 - INFO - Dataset size: 482\n",
      "2023-08-15 09:14:05,012 - INFO - model_path:  /scratch/fastscratch/NBL/trained_models/test/mini0\n",
      "2023-08-15 09:14:05,013 - INFO -    The 0 is the largest checkpoint!\n",
      "2023-08-15 09:14:05,014 - INFO - Dataset size: 482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ_CONFIG_FILE environment variable has not been set. Using default value: /home/ligeti/github/prokbert/src/prokbert/configs/sequence_processing.yaml\n",
      "/home/ligeti/github/prokbert/src/prokbert\n",
      "Loading the existing model from the chekcpoint\n"
     ]
    }
   ],
   "source": [
    "nr_gpus = count_gpus()\n",
    " \n",
    "tokenizer = get_training_tokenizer(prokbert_config)\n",
    "prokbert_dc = get_data_collator_for_overlapping_sequences(tokenizer, prokbert_config)\n",
    "hdf_file_exists, ds_size = check_hdf_dataset_file(prokbert_config)\n",
    "[m_exists, cp_dir, cp, cps] = check_model_existance_and_checkpoint(prokbert_config.model_params['model_outputpath'], \n",
    "                                     prokbert_config.model_params['model_name'])\n",
    "iteration_offset = get_the_iteration_offset(batch_size = prokbert_config.pretraining_params['per_device_train_batch_size'],\n",
    "                                           training_steps = cps[-1],\n",
    "                                           dataset_size = ds_size,\n",
    "                                           nr_gpus =nr_gpus,\n",
    "                                           radient_accumulation_steps = prokbert_config.pretraining_params['gradient_accumulation_steps'])\n",
    "training_dataset = IterableProkBERTPretrainingDataset(file_path=prokbert_config.dataset_params['dataset_path'],\n",
    "                                                     input_batch_size=prokbert_config.dataset_params['input_batch_size'],\n",
    "                                                     ds_offset=iteration_offset)\n",
    "\n",
    "\n",
    "if m_exists:\n",
    "    print('Loading the existing model from the chekcpoint')\n",
    "    expected_model_dir = cp_dir\n",
    "    model = MegatronBertForMaskedLM.from_pretrained(expected_model_dir)\n",
    "            \n",
    "else:\n",
    "    print('Investigating whether prevous model is exists')\n",
    "    [init_m_exists, init_m_cp_dir, init_m_cp, init_m_cps] = check_model_existance_and_checkpoint(prokbert_config.model_params['model_outputpath'], \n",
    "                                     prokbert_config.model_params['model_name'])\n",
    "\n",
    "\n",
    "\n",
    "# Get the training parameters:\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=prokbert_config.pretraining_params.pop('output_dir'),  # Explicitly pass the 'output_dir'\n",
    "    **prokbert_config.pretraining_params  # Pass the rest of the parameters\n",
    ")\n",
    "\n",
    "\n",
    "#prokbert_config.computation_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713d0f1-4e21-439e-90bd-1bed12bce01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.pretraining_params['adam_epsilon'].__class__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32832e3-c051-4b10-8c41-2f487115dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.pretraining_params['adam_epsilon']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec7cb3-3fd7-4106-b625-de51a50af5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d4fef-2cc0-4684-94a0-62a6ca8bb906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85f972-1eea-458d-9b28-bf58b781cee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643b4d5-b005-4d4f-9e4e-16429d3ab35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1127c-890b-4f76-bf23-94b3fa73b93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b4d85-989a-4c5c-808e-513530f54063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91def6db-3602-4064-85b5-aff3563f0580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a59b8-f668-41ba-b5c7-2e27f3c878c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.model_params\n",
    "\n",
    "[m_exists, cp_dir, cp, cps] = check_model_existance_and_checkpoint(prokbert_config.model_params['model_outputpath'], \n",
    "                                     prokbert_config.model_params['model_name'])\n",
    "# Conclusion: The current model extsts and can be resumed. \n",
    "\n",
    "# Cheking initiation model, if training required\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1befd96-abdd-4469-a761-c4dcc0f5708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking hdf dataset\n",
    "hdf_file_exists, ds_size = check_hdf_dataset_file(prokbert_config)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527b77c-e10c-4d4e-84d3-7053c41ec43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.dataset_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfd702-cbc5-450c-9867-a3da2e412b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9432-afff-494d-aa41-5ef51e714a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5babd-c5d9-4293-bd94-640aae2db126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a0bd8-5a1c-4803-a448-c66e41547814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the datacollator class!')\n",
    "prokbert_dc = ProkBERTDataCollator(tokenizer,\n",
    "                                  mask_to_left=prokbert_config.data_collator_params['mask_to_left'], \n",
    "                                  mask_to_right=prokbert_config.data_collator_params['mask_to_right'],\n",
    "                                  mlm_probability =   prokbert_config.data_collator_params['mlm_probability'],\n",
    "                                  replace_prob =prokbert_config.data_collator_params['replace_prob'],\n",
    "                                  random_prob = prokbert_config.data_collator_params['random_prob'])\n",
    "print(str(prokbert_dc))\n",
    "\n",
    "inputs, labels = prokbert_dc.torch_mask_tokens(ds[0:3][:,0:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ee3c5-a01e-4049-ad4c-2a6ff1cb47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.default_torchtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a78975-d81b-4e24-b072-60c9f9ac23c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129c4a2-1dad-434e-97d7-06482b3e1ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
