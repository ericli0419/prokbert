{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88222642-c405-4efd-beda-471c100cfe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PRETRAIN_CONFIG_FILE environment variable has not been set. Using default value: /home/ligeti/github/prokbert/src/prokbert/configs/pretraining.yaml\n",
      "SEQ_CONFIG_FILE environment variable has not been set. Using default value: /home/ligeti/github/prokbert/src/prokbert/configs/sequence_processing.yaml\n",
      "/home/ligeti/github/prokbert/src/prokbert\n",
      "/home/ligeti/github/prokbert/src/prokbert\n",
      "/home/ligeti/github/prokbert/src/prokbert\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "import pathlib\n",
    "from os.path import join\n",
    "import os\n",
    "import sys\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "current_path = str(pathlib.Path(os.getcwd()).parent)\n",
    "sys.path.append(current_path)\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('../)\n",
    "\n",
    "from config_utils import *\n",
    "from sequtils import *\n",
    "from training_utils import *\n",
    "from prokbert_tokenizer import ProkBERTTokenizer\n",
    "from prok_datasets import IterableProkBERTPretrainingDataset\n",
    "from general_utils import *\n",
    "from ProkBERTDataCollator import *\n",
    "from transformers import MegatronBertConfig, MegatronBertForMaskedLM, Trainer, TrainingArguments\n",
    "\n",
    "    \n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "#pd.set_option('display.width', 4000)\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_model_output_dir = ''\n",
    "train_model_name = 'LCA_repr_k6s1_l2048hs1536_h16_l16_mlm02_rp8_rndp1_rkv'\n",
    "\n",
    "model_params = {'model_outputpath': '/scratch/fastscratch/NBL/trained_models/test/prokbert-mini-k6s1',\n",
    "                'model_name' : 'prokbert-mini-k6s1'}\n",
    "dataset_params = {'dataset_path' : '../data/preprocessed/pretraining.h5'}\n",
    "pretraining_params = {}\n",
    "tokenization_params = {'kmer' : 6,\n",
    "                      'shift' : 1}\n",
    "segmentation_params = {}\n",
    "computation_params= {}\n",
    "prokbert_config = ProkBERTConfig()\n",
    "_ = prokbert_config.get_and_set_model_parameters(model_params)\n",
    "_ = prokbert_config.get_and_set_dataset_parameters(dataset_params)\n",
    "_ = prokbert_config.get_and_set_pretraining_parameters(pretraining_params)\n",
    "_ = prokbert_config.get_and_set_tokenization_parameters(tokenization_params)\n",
    "_ = prokbert_config.get_and_set_segmentation_parameters(segmentation_params)\n",
    "_ = prokbert_config.get_and_set_computation_params(computation_params)\n",
    "prokbert_config.default_torchtype = torch.int32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c41f7d-4b5e-4d2e-a990-834dd72948c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c73ec47-804e-4155-ab3c-08849c773eee",
   "metadata": {},
   "source": [
    "### Pretraining folyamata\n",
    "\n",
    "Vannak előkészítő feladatok:\n",
    "  * tokenizáló loadolása\n",
    "  * collator osztály loadolása\n",
    "  * Meglévő modellek ellenőrzése, checkpoint-ok ellenőrzése\n",
    "  * dataset betöltése és inicializálása, ellenőrzése (megfelel-e a követelményeknek vagy sem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf28f8e-e095-4444-a528-f7d48001d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2a7794-694e-46d1-a6af-ba61394f2d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 12:56:42,678 - INFO - Loading the datacollator class!\n",
      "2023-08-15 12:56:42,679 - INFO - Collator Parameters:\n",
      "  Number of tokens masked to left:  3\n",
      "  Number of tokens masked to right: 2\n",
      "  Probability of restoring a masked token: 0.8\n",
      "  Probability of changing to a random token: 0.01\n",
      "  MLM Probability: 0.05\n",
      "  Default token type: torch.int32\n",
      "\n",
      "2023-08-15 12:56:42,680 - INFO - Checking whether the file exists or not!\n",
      "2023-08-15 12:56:42,680 - INFO - Loading and creating a IterableProkBERTPretrainingDataset\n",
      "2023-08-15 12:56:42,682 - INFO - Dataset size: 482\n",
      "2023-08-15 12:56:42,683 - INFO - model_path:  /scratch/fastscratch/NBL/trained_models/test/prokbert-mini-k6s1\n",
      "2023-08-15 12:56:42,685 - INFO - Dataset size: 482\n",
      "2023-08-15 12:56:42,686 - INFO - model_path:  /scratch/fastscratch/NBL/trained_models/test/prokbert-mini-k6s1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ_CONFIG_FILE environment variable has not been set. Using default value: /home/ligeti/github/prokbert/src/prokbert/configs/sequence_processing.yaml\n",
      "/home/ligeti/github/prokbert/src/prokbert\n",
      "Loading the existing model from the chekcpoint folder: /scratch/fastscratch/NBL/trained_models/test/prokbert-mini-k6s1/checkpoint-470000\n"
     ]
    }
   ],
   "source": [
    "nr_gpus = count_gpus()\n",
    "\n",
    "# Get the training parameters:\n",
    "training_args = TrainingArguments(**prokbert_config.pretraining_params)\n",
    "\n",
    "tokenizer = get_training_tokenizer(prokbert_config)\n",
    "prokbert_dc = get_data_collator_for_overlapping_sequences(tokenizer, prokbert_config)\n",
    "hdf_file_exists, ds_size = check_hdf_dataset_file(prokbert_config)\n",
    "[m_exists, cp_dir, cp, cps] = check_model_existance_and_checkpoint(prokbert_config.model_params['model_outputpath'], \n",
    "                                     prokbert_config.model_params['model_name'])\n",
    "iteration_offset = get_the_iteration_offset(batch_size = prokbert_config.pretraining_params['per_device_train_batch_size'],\n",
    "                                           training_steps = cps[-1],\n",
    "                                           dataset_size = ds_size,\n",
    "                                           nr_gpus =nr_gpus,\n",
    "                                           radient_accumulation_steps = prokbert_config.pretraining_params['gradient_accumulation_steps'])\n",
    "training_dataset = IterableProkBERTPretrainingDataset(file_path=prokbert_config.dataset_params['dataset_path'],\n",
    "                                                     input_batch_size=prokbert_config.dataset_params['input_batch_size'],\n",
    "                                                     ds_offset=iteration_offset)\n",
    "\n",
    "model = get_pretrained_model(prokbert_config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prokbert_config.computation_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f713d0f1-4e21-439e-90bd-1bed12bce01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ligeti/huggingface/prokbert-mini-k6s1/tokenizer_config.json',\n",
       " '/home/ligeti/huggingface/prokbert-mini-k6s1/special_tokens_map.json',\n",
       " '/home/ligeti/huggingface/prokbert-mini-k6s1/vocab.txt',\n",
       " '/home/ligeti/huggingface/prokbert-mini-k6s1/added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_pretrained('/home/ligeti/huggingface/prokbert/prokbert-large-k6s1')\n",
    "\n",
    "#model.save_pretrained('/home/ligeti/huggingface/prokbert-mini-k6s1/')\n",
    "tokenizer.save_pretrained('/home/ligeti/huggingface/prokbert-mini-k6s1/')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32832e3-c051-4b10-8c41-2f487115dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained('/home/ligeti/huggingface/test_tokenizer/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cec7cb3-3fd7-4106-b625-de51a50af5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target hard link /home/ligeti/huggingface/prokbert-mini-k6s1/general_utils.py exist. Skipping...\n",
      "The target hard link /home/ligeti/huggingface/prokbert-mini-k6s1/prokbert_tokenizer.py exist. Skipping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hard links for specified files created in /home/ligeti/huggingface/prokbert-mini-k6s1/ from /home/ligeti/github/prokbert/src/prokbert.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its existing, delete or do sg about it if you want\n",
      "All hidden files removed from /home/ligeti/huggingface/prokbert-mini-k6s1/data.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "source_dir = '/home/ligeti/github/prokbert/src/prokbert'\n",
    "file_list =  ['general_utils.py', 'prokbert_tokenizer.py', 'config_utils.py']\n",
    "target_dir = '/home/ligeti/huggingface/prokbert-mini-k6s1/'\n",
    "vocab_data_dir_example = '/home/ligeti/github/prokbert/src/prokbert/data/prokbert_vocabs/prokbert-base-dna6/temp'\n",
    "vocab_data_source_dir = '/home/ligeti/github/prokbert/src/prokbert/data/prokbert_vocabs'\n",
    "target_vocab_dir = '/home/ligeti/huggingface/prokbert-mini-k6s1/data/prokbert_vocabs'\n",
    "\n",
    "\n",
    "\n",
    "create_selected_hard_links(source_dir, target_dir, file_list)\n",
    "#create_directory_for_filepath(vocab_data_dir_example)\n",
    "try:\n",
    "    shutil.copytree(vocab_data_source_dir, target_vocab_dir)\n",
    "except FileExistsError:\n",
    "    print('Its existing, delete or do sg about it if you want')\n",
    "remove_hidden_files(join(target_dir, 'data'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d4fef-2cc0-4684-94a0-62a6ca8bb906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85f972-1eea-458d-9b28-bf58b781cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643b4d5-b005-4d4f-9e4e-16429d3ab35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1127c-890b-4f76-bf23-94b3fa73b93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b4d85-989a-4c5c-808e-513530f54063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91def6db-3602-4064-85b5-aff3563f0580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a59b8-f668-41ba-b5c7-2e27f3c878c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.model_params\n",
    "\n",
    "[m_exists, cp_dir, cp, cps] = check_model_existance_and_checkpoint(prokbert_config.model_params['model_outputpath'], \n",
    "                                     prokbert_config.model_params['model_name'])\n",
    "# Conclusion: The current model extsts and can be resumed. \n",
    "\n",
    "# Cheking initiation model, if training required\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1befd96-abdd-4469-a761-c4dcc0f5708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking hdf dataset\n",
    "hdf_file_exists, ds_size = check_hdf_dataset_file(prokbert_config)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527b77c-e10c-4d4e-84d3-7053c41ec43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.dataset_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfd702-cbc5-450c-9867-a3da2e412b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9432-afff-494d-aa41-5ef51e714a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5babd-c5d9-4293-bd94-640aae2db126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a0bd8-5a1c-4803-a448-c66e41547814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the datacollator class!')\n",
    "prokbert_dc = ProkBERTDataCollator(tokenizer,\n",
    "                                  mask_to_left=prokbert_config.data_collator_params['mask_to_left'], \n",
    "                                  mask_to_right=prokbert_config.data_collator_params['mask_to_right'],\n",
    "                                  mlm_probability =   prokbert_config.data_collator_params['mlm_probability'],\n",
    "                                  replace_prob =prokbert_config.data_collator_params['replace_prob'],\n",
    "                                  random_prob = prokbert_config.data_collator_params['random_prob'])\n",
    "print(str(prokbert_dc))\n",
    "\n",
    "inputs, labels = prokbert_dc.torch_mask_tokens(ds[0:3][:,0:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ee3c5-a01e-4049-ad4c-2a6ff1cb47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prokbert_config.default_torchtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a78975-d81b-4e24-b072-60c9f9ac23c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129c4a2-1dad-434e-97d7-06482b3e1ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
